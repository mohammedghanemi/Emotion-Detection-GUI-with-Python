import os
import cv2
import tkinter as tk
from tkinter import filedialog
from tkinter import messagebox
import numpy as np
import matplotlib.pyplot as plt
from decord import VideoReader
from moviepy.editor import AudioFileClip
from scipy.io import wavfile
from scipy.fftpack import dct
from PIL import Image
import tensorflow as tf
import pyaudio
import wave


# Constants for image and video processing
input_size = 224
num_frame = 16  # We want 16 frames
sampling_rate = 6

# Load the saved model
model_path = "D:/saved_model"  # Update this path if necessary
model = tf.saved_model.load(model_path)

# Constants for emotion labels
uc_label2id = {'anger': 0, 'happiness': 1, 'surprise': 2, 'disgust': 3, 'fear': 4, 'sadness': 5}
uc_id2label = {v: k for k, v in uc_label2id.items()}

# Function to normalize audio
def normalize_audio(audio):
    audio = audio / np.max(np.abs(audio))
    return audio

# Function to calculate MFCC
def MFCC(signal, sample_rate):
    # Apply Short-Time Fourier Transform (STFT)
    NFFT = 512
    hop_size = 256
    window = np.hanning(NFFT)
    
    # Calculate magnitude of STFT
    stft = np.abs(np.fft.rfft(signal, NFFT, axis=-1))
    
    # Apply Mel-filterbank to STFT
    mel_filterbank = np.linspace(0, sample_rate//2, 40)
    
    # Apply Discrete Cosine Transform (DCT) to extract MFCCs
    mfcc = dct(stft, type=2, axis=-1, norm='ortho')[:13]
    
    return mfcc

# Function to read video frames
def read_video(file_path, num_frames=16):
    vr = VideoReader(file_path)
    total_frames = len(vr)
    frame_indices = np.linspace(0, total_frames-1, num_frames, dtype=int)  # evenly spaced frame indices
    
    frames = vr.get_batch(frame_indices).asnumpy()
    return format_frames(frames, output_size=(input_size, input_size))

# Function to format video frames
def format_frames(frames, output_size):
    # Convert frames to uint8 format
    frames = frames.astype(np.uint8)
    
    # Resize each frame to the desired size (224x224)
    frames_resized = np.array([cv2.resize(frame, (output_size[0], output_size[1])) for frame in frames])
    
    # Ensure we have 16 frames with shape [16, 224, 224, 3]
    frames_resized = frames_resized[:16]  # Just to be safe, ensure 16 frames are returned
    
    # Add an additional dimension for channels (RGB)
    return frames_resized

# Function to process video and audio
def process_video_and_audio(input_path):
    # Process video frames
    video_frames = read_video(input_path, num_frames=num_frame)
    video_shape = video_frames.shape  # This should return (16, 224, 224, 3)
    
    # Process audio (assuming we extract audio from the video)
    audio_path = input_path.replace('.mp4', '.wav')  # Assuming the video file has an audio track
    audio_clip = AudioFileClip(input_path)
    audio_clip.write_audiofile(audio_path)
    
    # Read the audio and normalize
    sample_rate, audio_signal = wavfile.read(audio_path)
    audio_signal = normalize_audio(audio_signal)
    
    # Calculate MFCC for the audio
    mfcc_features = MFCC(audio_signal, sample_rate)
    
    # Perform emotion detection using the model
    emotion = predict_emotion(video_frames)
    
    return f"Processed file size: {video_shape[0]} frames, {input_size}x{input_size} pixels each, Predicted Emotion: {emotion}"

# Function to predict emotion using the model
def predict_emotion(video_frames):
    video_frames = np.expand_dims(video_frames, axis=0)  # Add batch dimension
    video_frames = tf.convert_to_tensor(video_frames, dtype=tf.float32)

    # Run the model prediction
    predictions = model(video_frames)
    predicted_class = np.argmax(predictions, axis=-1)[0]
    
    # Map the prediction to the emotion label
    emotion = uc_id2label[predicted_class]
    return emotion



# GUI setup using tkinter
def create_gui():
    # Creating the main window
    window = tk.Tk()
    window.title("Emotion Detection GUI")
    
    # Function to open file dialog and load a file
    def load_file():
        file_path = filedialog.askopenfilename(title="Select Video File", filetypes=[("Video files", "*.mp4 *.avi")])
        if file_path:
            # Display the file path in the label
            loaded_file_label.config(text=f"Loaded File: {os.path.basename(file_path)}")
            # Process the file
            result = process_video_and_audio(file_path)
            processed_file_label.config(text=f"Processed File Info: {result}")
        else:
            messagebox.showwarning("File Not Selected", "Please select a valid video file.")

    # Creating the load button
    load_button = tk.Button(window, text="Load Video File", command=load_file)
    load_button.pack(pady=20)

    # Label to show the loaded file name
    loaded_file_label = tk.Label(window, text="Loaded File: None")
    loaded_file_label.pack(pady=10)

    # Label to show the processed file information
    processed_file_label = tk.Label(window, text="Processed File Info: None")
    processed_file_label.pack(pady=10)

    # Running the Tkinter event loop
    window.mainloop()

# Run the GUI
create_gui()
